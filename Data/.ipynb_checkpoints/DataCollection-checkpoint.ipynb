{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8d9b23-5459-452a-ad3e-1e9bf0187e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.1.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->SPARQLWrapper) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca58313d-3f2a-40d3-b851-d7aaddc03fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bbdf679-1f40-4af5-8ff3-740dd31ea15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the subclasses list\n",
    "subclasses = []\n",
    "\n",
    "# Initialize SPARQL endpoint\n",
    "dbpedia_sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "\n",
    "# Define the SPARQL query\n",
    "dbpedia_sparql.setQuery(\"\"\"\n",
    "   SELECT ?subclass (COUNT(DISTINCT ?instance) AS ?count)\n",
    "   WHERE {\n",
    "     ?instance a ?subclass.\n",
    "     ?subclass rdfs:subClassOf dbo:Person.\n",
    "     FILTER (?subclass != dbo:Person)\n",
    "     OPTIONAL {\n",
    "        ?instance schema:about ?wikiPage .\n",
    "        ?wikiPage foaf:isPrimaryTopicOf ?article .\n",
    "        FILTER(STRSTARTS(STR(?article), \"https://en.wikipedia.org\"))\n",
    "        FILTER(LANG(?article) = \"en\")\n",
    "     }\n",
    "   }\n",
    "   GROUP BY ?subclass\n",
    "   ORDER BY ASC(?count)\n",
    "\"\"\")\n",
    "\n",
    "# Set return format to JSON\n",
    "dbpedia_sparql.setReturnFormat(JSON)\n",
    "\n",
    "# Execute the query and process the results\n",
    "results = dbpedia_sparql.query().convert()\n",
    "\n",
    "subclasses = {}\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    subclass_uri = result[\"subclass\"][\"value\"]\n",
    "    count = result[\"count\"][\"value\"]\n",
    "    subclass = subclass_uri.replace(\"http://dbpedia.org/ontology/\", \"\")\n",
    "    subclasses[subclass] = int(count)  # Convert count to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52fa5eb-def7-4fc4-bc82-54e520e29d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Judge': 124,\n",
       " 'Monarch': 245,\n",
       " 'Spy': 261,\n",
       " 'AmericanLeader': 264,\n",
       " 'Pilot': 286,\n",
       " 'HorseTrainer': 355,\n",
       " 'PoliceOfficer': 413,\n",
       " 'Presenter': 670,\n",
       " 'BusinessPerson': 691,\n",
       " 'Astronaut': 738,\n",
       " 'Engineer': 885,\n",
       " 'Chef': 897,\n",
       " 'Youtuber': 900,\n",
       " 'PlayboyPlaymate': 979,\n",
       " 'Economist': 1720,\n",
       " 'Journalist': 1858,\n",
       " 'Model': 2045,\n",
       " 'BeautyQueen': 2987,\n",
       " 'Philosopher': 2987,\n",
       " 'Religious': 4832,\n",
       " 'Architect': 5574,\n",
       " 'Criminal': 6081,\n",
       " 'Noble': 7949,\n",
       " 'Academic': 10663,\n",
       " 'Coach': 10954,\n",
       " 'Royalty': 22720,\n",
       " 'Cleric': 25434,\n",
       " 'SportsManager': 29156,\n",
       " 'MilitaryPerson': 50255,\n",
       " 'Writer': 51821,\n",
       " 'Scientist': 52119,\n",
       " 'OfficeHolder': 66597,\n",
       " 'Artist': 107644,\n",
       " 'Politician': 200848,\n",
       " 'OrganisationMember': 456914,\n",
       " 'Athlete': 578933}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77653f2c-23da-43a3-b02c-ebfd7c363373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456914"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclasses.pop(\"OrganisationMember\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610bbbe7-1281-42d9-8df9-00a26749cd40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Judge': 124,\n",
       " 'Monarch': 245,\n",
       " 'Spy': 261,\n",
       " 'AmericanLeader': 264,\n",
       " 'Pilot': 286,\n",
       " 'HorseTrainer': 355,\n",
       " 'PoliceOfficer': 413,\n",
       " 'Presenter': 670,\n",
       " 'BusinessPerson': 691,\n",
       " 'Astronaut': 738,\n",
       " 'Engineer': 885,\n",
       " 'Chef': 897,\n",
       " 'Youtuber': 900,\n",
       " 'PlayboyPlaymate': 979,\n",
       " 'Economist': 1720,\n",
       " 'Journalist': 1858,\n",
       " 'Model': 2045,\n",
       " 'BeautyQueen': 2987,\n",
       " 'Philosopher': 2987,\n",
       " 'Religious': 4832,\n",
       " 'Architect': 5574,\n",
       " 'Criminal': 6081,\n",
       " 'Noble': 7949,\n",
       " 'Academic': 10663,\n",
       " 'Coach': 10954,\n",
       " 'Royalty': 22720,\n",
       " 'Cleric': 25434,\n",
       " 'SportsManager': 29156,\n",
       " 'MilitaryPerson': 50255,\n",
       " 'Writer': 51821,\n",
       " 'Scientist': 52119,\n",
       " 'OfficeHolder': 66597,\n",
       " 'Artist': 107644,\n",
       " 'Politician': 200848,\n",
       " 'Athlete': 578933}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eacd8290-d3b9-4b73-9951-fec7d47c430e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to get the year of the first publication date of an article\n",
    "def publication_year_MediaWiki(article_title):\n",
    "    url = f\"https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvlimit=1&rvprop=timestamp&rvdir=newer&titles={article_title}&format=json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:  # Check if the request was successful\n",
    "        try:\n",
    "            data = response.json()\n",
    "            if \"query\" in data and \"pages\" in data[\"query\"]:\n",
    "                page_id = list(data[\"query\"][\"pages\"].keys())[0]  # Extract page ID\n",
    "                revisions = data[\"query\"][\"pages\"][page_id][\"revisions\"]\n",
    "                if revisions:\n",
    "                    timestamp = revisions[0][\"timestamp\"]  # Get the timestamp\n",
    "                    # Parse the timestamp string and extract the year\n",
    "                    year = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "                    return year  # Return the year\n",
    "            return None  # If there are no revisions or unexpected JSON structure, return None\n",
    "        except Exception as e:\n",
    "            # print(\"Error parsing JSON:\", e)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb12ed90-6c2c-4292-9387-5d8412fc5639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_gender_from_wikidata(wikidata_id):\n",
    "    # Initialize SPARQL endpoint\n",
    "    wikidata_sparql = SPARQLWrapper('https://query.wikidata.org/sparql')\n",
    "    # Define the endpoint and the query\n",
    "    query = f\"\"\"\n",
    "    SELECT ?genderLabel WHERE {{\n",
    "      wd:{wikidata_id} wdt:P21 ?gender.\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the SPARQL wrapper\n",
    "    wikidata_sparql.setQuery(query)\n",
    "    wikidata_sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        # Execute the query and fetch results\n",
    "        results = wikidata_sparql.query().convert()\n",
    "        # Extract the gender label from the results\n",
    "        if results[\"results\"][\"bindings\"]:\n",
    "            gender = results[\"results\"][\"bindings\"][0][\"genderLabel\"][\"value\"]\n",
    "            return gender\n",
    "        else:\n",
    "            return None\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error: {e}\")\n",
    "    #     return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. Retrying after 2 seconds...\")\n",
    "        time.sleep(2)\n",
    "        get_gender_from_wikidata(wikidata_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a803d28e-4869-4883-bd71-89c397340b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retries = 2\n",
    "\n",
    "def run_code(subclass, i, offset):\n",
    "    # Initialize SPARQL endpoint\n",
    "    dbpedia_sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "    \n",
    "    # Initialize an empty list to store data\n",
    "    data_list = []\n",
    "    \n",
    "    # Define the SPARQL query\n",
    "    dbpedia_sparql.setQuery(f\"\"\"\n",
    "    SELECT ?instance ?wikidataID ?calculatedAge ?birthYear\n",
    "    WHERE {{\n",
    "        SELECT DISTINCT ?instance ?wikidataID ?calculatedAge ?birthYear \n",
    "        WHERE {{\n",
    "            ?instance rdf:type dbo:{subclass} .\n",
    "            OPTIONAL {{ ?instance dbo:birthDate ?birthDate }}\n",
    "            OPTIONAL {{ ?instance dbo:age ?age }}\n",
    "            OPTIONAL {{ ?instance dbo:deathDate ?deathDate }}\n",
    "            OPTIONAL {{\n",
    "                ?instance owl:sameAs ?wikidataID .\n",
    "                FILTER regex(str(?wikidataID), \"wikidata.org/entity/\")\n",
    "            }}\n",
    "            OPTIONAL {{\n",
    "                ?instance schema:about ?wikiPage .\n",
    "                ?wikiPage foaf:isPrimaryTopicOf ?article .\n",
    "                FILTER(STRSTARTS(STR(?article), \"https://en.wikipedia.org\"))\n",
    "                FILTER(LANG(?article) = \"en\")\n",
    "            }}\n",
    "    \n",
    "            # Bind year only if birthDate is available and is a valid date\n",
    "            BIND(IF(BOUND(?birthDate), YEAR(?birthDate), UNDEF) AS ?birthYear)\n",
    "                \n",
    "            # Bind calculatedAge only if birthYear is valid\n",
    "            BIND(IF(BOUND(?age), ?age, \n",
    "                    IF(BOUND(?deathDate) , \n",
    "                        (YEAR(?deathDate) - IF(BOUND(?birthYear), ?birthYear, YEAR(NOW()))), \n",
    "                        (YEAR(NOW()) - IF(BOUND(?birthYear), ?birthYear, YEAR(NOW())))\n",
    "                    )) AS ?calculatedAge)\n",
    "            }}\n",
    "            ORDER BY ?instance\n",
    "        }}\n",
    "        OFFSET {offset}\n",
    "        LIMIT 10000\n",
    "    \"\"\")\n",
    "\n",
    "    # Define the query format\n",
    "    dbpedia_sparql.setReturnFormat(JSON)\n",
    "    dbpedia_sparql.setTimeout(60)  # Set timeout\n",
    "    \n",
    "    attempts = 0\n",
    "    while attempts < retries:\n",
    "        try:\n",
    "            # Execute the query and parse the results\n",
    "            results = dbpedia_sparql.query().convert()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(f\"{e}, internal retrying... ({attempts}/{retries})\")\n",
    "            time.sleep(2)\n",
    "            if attempts == retries:\n",
    "                raise e\n",
    "    \n",
    "    # Execute the query and parse the results\n",
    "    results = dbpedia_sparql.query().convert()\n",
    "\n",
    "    # Iterate over the results and populate the data list\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        wikiDataID = result[\"wikidataID\"][\"value\"].replace(\"http://www.wikidata.org/entity/\", \"\") if \"wikidataID\" in result else None\n",
    "        gender = get_gender_from_wikidata(wikiDataID)\n",
    "        instance = result[\"instance\"][\"value\"].replace(\"http://dbpedia.org/resource/\", \"\") \n",
    "        birth_year = int(result[\"birthYear\"][\"value\"].replace(\"http://dbpedia.org/resource/\", \"\")) if \"birth_year\" in result else None\n",
    "        age = result[\"calculatedAge\"][\"value\"].replace(\"http://dbpedia.org/resource/\", \"\")\n",
    "        publication_year = publication_year_MediaWiki(instance)\n",
    "        data_list.append({'subclass': subclass, 'instance': instance, 'wikiDataID':wikiDataID, 'gender':gender,'age':int(age), 'birthYear':birth_year,'publication_year': publication_year})\n",
    "        \n",
    "    # Create DataFrame from the data list\n",
    "    df = pd.DataFrame(data_list)\n",
    "    \n",
    "    df.to_csv(f\"{subclass}/{subclass}iteration{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3fe2d8-8273-4da2-a039-5bf761afb4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration 0 ..... for subclass Judge\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m attempts \u001b[38;5;241m<\u001b[39m retries:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m         \u001b[43mrun_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mrun_code\u001b[0;34m(subclass, i, offset)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     69\u001b[0m     wikiDataID \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikidataID\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.wikidata.org/entity/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwikidataID\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     gender \u001b[38;5;241m=\u001b[39m \u001b[43mget_gender_from_wikidata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwikiDataID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     instance \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://dbpedia.org/resource/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     72\u001b[0m     birth_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbirthYear\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://dbpedia.org/resource/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbirth_year\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mget_gender_from_wikidata\u001b[0;34m(wikidata_id)\u001b[0m\n\u001b[1;32m     16\u001b[0m wikidata_sparql\u001b[38;5;241m.\u001b[39msetReturnFormat(JSON)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Execute the query and fetch results\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mwikidata_sparql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Extract the gender label from the results\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbindings\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/SPARQLWrapper/Wrapper.py:960\u001b[0m, in \u001b[0;36mSPARQLWrapper.query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryResult\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    943\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    Execute the query.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    Exceptions can be raised if either the URI is wrong or the HTTP sends back an error (this is also the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`QueryResult` instance\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/SPARQLWrapper/Wrapper.py:926\u001b[0m, in \u001b[0;36mSPARQLWrapper._query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    924\u001b[0m         response \u001b[38;5;241m=\u001b[39m urlopener(request, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43murlopener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnFormat\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/urllib/request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1354\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retries = 5\n",
    "for subclass in subclasses:\n",
    "    offsets = range(0, subclasses[subclass]+1, 10000)\n",
    "    i = 0\n",
    "    for offset in offsets:\n",
    "        print(\"Running iteration\", i, \"..... for subclass\", subclass)\n",
    "        attempts = 0\n",
    "        while attempts < retries:\n",
    "            try:\n",
    "                run_code(subclass, i, offset)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempts += 1\n",
    "                print(f\"{e}, main retrying... ({attempts}/{retries})\")\n",
    "                time.sleep(2)\n",
    "                if attempts == retries:\n",
    "                    raise e\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c9968-9464-4c0e-898e-158f2766c451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0d342-1b0e-42ec-bd0a-f170e05d4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for key, val in subclasses.items():\n",
    "    if val < 400000:\n",
    "        total += val\n",
    "print(total + )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ad86c-0140-467a-9372-b2604116bcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
